{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/defyMiy/NMT-Project/blob/main/mbart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training MBART model"
      ],
      "metadata": {
        "id": "Y7CqqUPuxQf2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuGVjDl4T_Rg"
      },
      "outputs": [],
      "source": [
        "# check GPU avaliable\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install package\n",
        "# mount to drive if dataset in google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install simpletransformers\n",
        "!pip install torch\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "ymuUz6cOK02u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6Hj8ljEmqlz"
      },
      "outputs": [],
      "source": [
        "# config model\n",
        "\n",
        "import logging\n",
        "import torch\n",
        "import pandas as pd\n",
        "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# load dataset\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/train.csv').astype(str)\n",
        "eval_df = pd.read_csv('/content/gdrive/MyDrive/eval.csv').astype(str)\n",
        "train_df[\"prefix\"] = \"\"\n",
        "eval_df[\"prefix\"] = \"\"\n",
        "\n",
        "# config parameter\n",
        "BATCH_SIZE = 4\n",
        "EPOCH = 4\n",
        "LEARNING_RATE = 4e-5\n",
        "PROJECT_NAME = 'MBART Machine Translation'\n",
        "\n",
        "model_args = Seq2SeqArgs()\n",
        "model_args.train_batch_size = BATCH_SIZE\n",
        "model_args.eval_batch_size = BATCH_SIZE\n",
        "model_args.num_train_epochs = EPOCH\n",
        "model_args.learning_rate = LEARNING_RATE\n",
        "model_args.max_seq_length = 512\n",
        "model_args.max_length = 100\n",
        "model_args.evaluate_during_training = True\n",
        "model_args.evaluate_during_training_steps = 300000\n",
        "model_args.use_multiprocessing = False\n",
        "model_args.fp16 = False\n",
        "model_args.save_steps = -1\n",
        "model_args.save_eval_checkpoints = False\n",
        "model_args.no_cache = True\n",
        "model_args.reprocess_input_data = True\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.preprocess_inputs = False\n",
        "model_args.num_return_sequences = 1\n",
        "model_args.wandb_project = PROJECT_NAME\n",
        "\n",
        "# use GPU if available\n",
        "device = torch.cuda.is_available()\n",
        "\n",
        "model = Seq2SeqModel(encoder_decoder_type=\"mbart\",\n",
        "                     encoder_decoder_name=\"facebook/mbart-large-50\",\n",
        "                     args=model_args,\n",
        "                     use_cuda=device)\n",
        "\n",
        "# website for more model\n",
        "# https://huggingface.co/models?sort=downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC3UPgobn09n"
      },
      "outputs": [],
      "source": [
        "!rm -rf '/content/outputs'\n",
        "!rm -rf '/content/runs'\n",
        "!rm -rf '/content/wandb'\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df, eval_data=eval_df)\n",
        "\n",
        "# Evaluate the model\n",
        "result = model.eval_model(eval_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uXZ3gHYpL8g"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "\n",
        "import logging\n",
        "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "model_args = Seq2SeqArgs()\n",
        "model_args.max_length = 100\n",
        "model_args.length_penalty = 1\n",
        "model_args.num_beams = 10\n",
        "\n",
        "device = torch.cuda.is_available()\n",
        "\n",
        "# path model\n",
        "PATH = '/content/outputs'\n",
        "\n",
        "model = Seq2SeqModel(encoder_decoder_type=\"mbart\",\n",
        "                     encoder_decoder_name=PATH,\n",
        "                     args=model_args,\n",
        "                     use_cuda=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Ebi6GCujwd"
      },
      "outputs": [],
      "source": [
        "# calculate bleu score\n",
        "\n",
        "import sacrebleu\n",
        "import pandas as pd\n",
        "\n",
        "# load test data\n",
        "test = pd.read_csv(\"/content/test.csv\").astype(str)\n",
        "thai_truth = [test.loc[test[\"prefix\"] == \"translate english to thai\"][\"target_text\"].tolist()]\n",
        "to_thai = test.loc[test[\"prefix\"] == \"translate english to thai\"][\"input_text\"].tolist()\n",
        "english_truth = [test.loc[test[\"prefix\"] == \"translate thai to english\"][\"target_text\"].tolist()]\n",
        "to_english = test.loc[test[\"prefix\"] == \"translate thai to english\"][\"input_text\"].tolist()\n",
        "\n",
        "# calculate BLEU score\n",
        "english_preds = model.predict(to_english)\n",
        "then_bleu = sacrebleu.corpus_bleu(english_preds, english_truth)\n",
        "print(\"Thai to English: \", then_bleu.score)\n",
        "thai_preds = model.predict(to_thai)\n",
        "enth_bleu = sacrebleu.corpus_bleu(thai_preds, thai_truth)\n",
        "print(\"English to Thai: \", enth_bleu.score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPt9RgwU9N98"
      },
      "outputs": [],
      "source": [
        "# test prediction Thai to English\n",
        "\n",
        "to_predict = ['โครงงานวิศวกรรมนี้เป็นการพัฒนาระบบตรวจจับ',\n",
        "              'และจําแนกโรคพืชจากภาพถ่ายใบพืชเมล่อนด้วยการเรียนรู้เชิงลึก',\n",
        "              'โดยใช้เครื่อง Jetson Nano ในการประมวลผลภาพจากกล้องในโรงเรือน',\n",
        "              'ซึ่งในการพัฒนาแบบจําลองการเรียนรู้เชิงลึกมีการเก็บรวบรวมภาพของใบเมล่อนจากโรงเรือน',\n",
        "              'และจัดทําสัญลักษณ์ความผิดปกติของใบเมล่อน',\n",
        "              'แล้วนําชุดข้อมูลที่ได้ไปใช้ในการฝึกแบบจําลองตรวจจับวัตถุในภาพ (Object Detector)',\n",
        "              'ซึ่งจะสามารถตรวจพบความผิดปกติของใบเมล่อน',\n",
        "              'และเมื่อระบบตรวจพบความผิดปกติจะแจ้งเตือนไปยังผู้ดูแลผ่านแอปพลิเคชันไลน์',\n",
        "              'ในขั้นตอนการเลือกแบบจําลองการเรียนรู้เชิงลึกเพื่อนําไปประมวลผลบนเครื่อง Jetson Nano']\n",
        "\n",
        "predictions = model.predict(to_predict)\n",
        "for i, info in enumerate(predictions):\n",
        "  print(to_predict[i] + '\\n' + info + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test prediction English to Thai\n",
        "\n",
        "to_predict2 = ['This engineering project develops a system for detecting. ',\n",
        "              'and classifying plant disease from photographs of melon leaves using deep learning.',\n",
        "              'The system uses NVIDIA Jetson Nano to process images from cameras in the greenhouse.',\n",
        "              'To develop a deep learning model, the images of the melon leaves from the greenhouses were collected.',\n",
        "              'and the melon leaf disease were labelled.',\n",
        "              'Then use the dataset to train the object detector model.',\n",
        "              'which will be able to detect disease in melon leaves.',\n",
        "              'and when the system detects a disease, the caretaker will be notified of the issue through the LINE application.',\n",
        "              'In the process of selecting a deep learning model to be deployed on the Jetson Nano.']\n",
        "\n",
        "predictions2 = model.predict(to_predict2)\n",
        "for i, info in enumerate(predictions2):\n",
        "  print(to_predict2[i] + '\\n' + info + '\\n')"
      ],
      "metadata": {
        "id": "NMntX8Ky5q3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNbBqiX2xuIHiWyJ7R3o//T",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}