{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask App Tutorial.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/defyMiy/NMT-Project/blob/main/hosting%20server%20in%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "69pvKnpzCP1p",
        "outputId": "3fdd2463-e053-4e71-af20-a6204b77df3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers\n",
        "!pip install torch\n",
        "!pip install pythainlp\n",
        "!pip install python-crfsuite"
      ],
      "metadata": {
        "id": "na1ddGhxCOw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf '/content/ngrok-stable-linux-amd64.tgz'\n",
        "!rm -rf '/content/ngrok'\n",
        "\n",
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet\n",
        "\n",
        "# install ngrok linux version using the following command or you can get the\n",
        "# latest version from its official website- https://dashboard.ngrok.com/get-started/setup\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
        "\n",
        "# extract the downloaded file using the following command \n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz\n",
        "\n",
        "# paste your AuthToken here and execute this command\n",
        "!./ngrok authtoken 23H0IY10fqeKMIW7kG05JhKZMae_3Zabr2iqkU9AUcZ7CrRTP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1HlxLaRJ-uv",
        "outputId": "9b6ff49f-dbbd-45e1-b326-5b88ca0c0634"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-22 05:59:52--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13856790 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.tgz’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.21M  19.1MB/s    in 0.7s    \n",
            "\n",
            "2023-05-22 05:59:53 (19.1 MB/s) - ‘ngrok-stable-linux-amd64.tgz’ saved [13856790/13856790]\n",
            "\n",
            "ngrok\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torch\n",
        "from simpletransformers.t5 import T5Model, T5Args\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "model_args = T5Args()\n",
        "model_args.max_length = 100\n",
        "model_args.length_penalty = 1\n",
        "model_args.num_beams = 10\n",
        "\n",
        "device = torch.cuda.is_available()\n",
        "path = '/content/gdrive/MyDrive/model/mt5-4bs-4e-5lr'\n",
        "\n",
        "model = T5Model(\"mt5\", path, args=model_args, use_cuda=device)"
      ],
      "metadata": {
        "id": "dEajrG6gAf3M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pycrfsuite\n",
        "from pythainlp import sent_tokenize\n",
        "\n",
        "def split_sentence_TH(TH_predict):\n",
        "  TH_predict = sent_tokenize(TH_predict)\n",
        "  for i in range(len(TH_predict)):\n",
        "    # remove space in back\n",
        "    TH_predict[i] = TH_predict[i].rstrip()\n",
        "\n",
        "    # debug for engine fail example ['750ml', '1500ml']\n",
        "    # move to append previous sentences\n",
        "    # and replace ''\n",
        "    if re.search('[0-9]', TH_predict[i][0]):\n",
        "      j = i\n",
        "      while True:\n",
        "        if TH_predict[j-1] != '':\n",
        "          TH_predict[j-1] += ' ' + TH_predict[i]\n",
        "          break\n",
        "      j -= 1\n",
        "      TH_predict[i] = ''\n",
        "\n",
        "  # remove '' in list\n",
        "  while '' in TH_predict:\n",
        "    TH_predict.remove('')\n",
        "  print('[split sentence completed]')\n",
        "  print(TH_predict)\n",
        "  return TH_predict\n",
        "\n",
        "def predict(text):\n",
        "  predictions = model.predict(text)\n",
        "  print('[split sentence completed]')\n",
        "  print(predictions)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "Xad5rlk563qu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import Flask from flask module\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# import run_with_ngrok from flask_ngrok to run the app using ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "  \n",
        "app = Flask(__name__) #app name\n",
        "run_with_ngrok(app)\n",
        "  \n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "  if request.method == \"POST\":\n",
        "    json_data = request.get_json()\n",
        "    if not json_data:\n",
        "      return jsonify({\"error\": \"no data\"})\n",
        "    try:\n",
        "      if json_data[\"task\"] == \"th-en\":\n",
        "        prediction = split_sentence_TH(json_data[\"text\"])\n",
        "        prediction = predict(prediction)\n",
        "        data_predicted = {\"prediction\": prediction}\n",
        "        return jsonify(data_predicted)\n",
        "        print('[returned data]')\n",
        "    except Exception as e:\n",
        "      return jsonify({\"error\": str(e)})\n",
        "  return \"OK\"\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "  app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLlugcOeKlWH",
        "outputId": "3aec69ce-d117-4251-c124-022b208938be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 174, in _new_conn\n",
            "    conn = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 398, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 244, in request\n",
            "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1283, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1329, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 205, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 186, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa7e19ebbb0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 440, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 592, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa7e19ebbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1378, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 75, in get\n",
            "    return request('get', url, params=params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 61, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 529, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 645, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa7e19ebbb0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uYZmmFj9qni"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}